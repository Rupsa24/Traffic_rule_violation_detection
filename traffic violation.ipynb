{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93135915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading weights of convolution #0\n",
      "loading weights of convolution #1\n",
      "loading weights of convolution #2\n",
      "loading weights of convolution #3\n",
      "no convolution #4\n",
      "loading weights of convolution #5\n",
      "loading weights of convolution #6\n",
      "loading weights of convolution #7\n",
      "no convolution #8\n",
      "loading weights of convolution #9\n",
      "loading weights of convolution #10\n",
      "no convolution #11\n",
      "loading weights of convolution #12\n",
      "loading weights of convolution #13\n",
      "loading weights of convolution #14\n",
      "no convolution #15\n",
      "loading weights of convolution #16\n",
      "loading weights of convolution #17\n",
      "no convolution #18\n",
      "loading weights of convolution #19\n",
      "loading weights of convolution #20\n",
      "no convolution #21\n",
      "loading weights of convolution #22\n",
      "loading weights of convolution #23\n",
      "no convolution #24\n",
      "loading weights of convolution #25\n",
      "loading weights of convolution #26\n",
      "no convolution #27\n",
      "loading weights of convolution #28\n",
      "loading weights of convolution #29\n",
      "no convolution #30\n",
      "loading weights of convolution #31\n",
      "loading weights of convolution #32\n",
      "no convolution #33\n",
      "loading weights of convolution #34\n",
      "loading weights of convolution #35\n",
      "no convolution #36\n",
      "loading weights of convolution #37\n",
      "loading weights of convolution #38\n",
      "loading weights of convolution #39\n",
      "no convolution #40\n",
      "loading weights of convolution #41\n",
      "loading weights of convolution #42\n",
      "no convolution #43\n",
      "loading weights of convolution #44\n",
      "loading weights of convolution #45\n",
      "no convolution #46\n",
      "loading weights of convolution #47\n",
      "loading weights of convolution #48\n",
      "no convolution #49\n",
      "loading weights of convolution #50\n",
      "loading weights of convolution #51\n",
      "no convolution #52\n",
      "loading weights of convolution #53\n",
      "loading weights of convolution #54\n",
      "no convolution #55\n",
      "loading weights of convolution #56\n",
      "loading weights of convolution #57\n",
      "no convolution #58\n",
      "loading weights of convolution #59\n",
      "loading weights of convolution #60\n",
      "no convolution #61\n",
      "loading weights of convolution #62\n",
      "loading weights of convolution #63\n",
      "loading weights of convolution #64\n",
      "no convolution #65\n",
      "loading weights of convolution #66\n",
      "loading weights of convolution #67\n",
      "no convolution #68\n",
      "loading weights of convolution #69\n",
      "loading weights of convolution #70\n",
      "no convolution #71\n",
      "loading weights of convolution #72\n",
      "loading weights of convolution #73\n",
      "no convolution #74\n",
      "loading weights of convolution #75\n",
      "loading weights of convolution #76\n",
      "loading weights of convolution #77\n",
      "loading weights of convolution #78\n",
      "loading weights of convolution #79\n",
      "loading weights of convolution #80\n",
      "loading weights of convolution #81\n",
      "no convolution #82\n",
      "no convolution #83\n",
      "loading weights of convolution #84\n",
      "no convolution #85\n",
      "no convolution #86\n",
      "loading weights of convolution #87\n",
      "loading weights of convolution #88\n",
      "loading weights of convolution #89\n",
      "loading weights of convolution #90\n",
      "loading weights of convolution #91\n",
      "loading weights of convolution #92\n",
      "loading weights of convolution #93\n",
      "no convolution #94\n",
      "no convolution #95\n",
      "loading weights of convolution #96\n",
      "no convolution #97\n",
      "no convolution #98\n",
      "loading weights of convolution #99\n",
      "loading weights of convolution #100\n",
      "loading weights of convolution #101\n",
      "loading weights of convolution #102\n",
      "loading weights of convolution #103\n",
      "loading weights of convolution #104\n",
      "loading weights of convolution #105\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tkinter as tk\n",
    "from keras.layers import Conv2D, Input, BatchNormalization, LeakyReLU, ZeroPadding2D, UpSampling2D\n",
    "from keras.layers import add, concatenate\n",
    "from keras.models import Model\n",
    "import struct\n",
    "import cv2\n",
    "\n",
    "class WeightReader:\n",
    "    def __init__(self, weight_file):\n",
    "        with open(weight_file, 'rb') as w_f:\n",
    "            major,    = struct.unpack('i', w_f.read(4))\n",
    "            minor,    = struct.unpack('i', w_f.read(4))\n",
    "            revision, = struct.unpack('i', w_f.read(4))\n",
    "\n",
    "            if (major*10 + minor) >= 2 and major < 1000 and minor < 1000:\n",
    "                w_f.read(8)\n",
    "            else:\n",
    "                w_f.read(4)\n",
    "\n",
    "            transpose = (major > 1000) or (minor > 1000)\n",
    "            \n",
    "            binary = w_f.read()\n",
    "\n",
    "        self.offset = 0\n",
    "        self.all_weights = np.frombuffer(binary, dtype='float32')\n",
    "        \n",
    "    def read_bytes(self, size):\n",
    "        self.offset = self.offset + size\n",
    "        return self.all_weights[self.offset-size:self.offset]\n",
    "\n",
    "    def load_weights(self, model):\n",
    "        for i in range(106):\n",
    "            try:\n",
    "                conv_layer = model.get_layer('conv_' + str(i))\n",
    "                print(\"loading weights of convolution #\" + str(i))\n",
    "\n",
    "                if i not in [81, 93, 105]:\n",
    "                    norm_layer = model.get_layer('bnorm_' + str(i))\n",
    "\n",
    "                    size = np.prod(norm_layer.get_weights()[0].shape)\n",
    "\n",
    "                    beta  = self.read_bytes(size) # bias\n",
    "                    gamma = self.read_bytes(size) # scale\n",
    "                    mean  = self.read_bytes(size) # mean\n",
    "                    var   = self.read_bytes(size) # variance            \n",
    "\n",
    "                    weights = norm_layer.set_weights([gamma, beta, mean, var])  \n",
    "\n",
    "                if len(conv_layer.get_weights()) > 1:\n",
    "                    bias   = self.read_bytes(np.prod(conv_layer.get_weights()[1].shape))\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    \n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel, bias])\n",
    "                else:\n",
    "                    kernel = self.read_bytes(np.prod(conv_layer.get_weights()[0].shape))\n",
    "                    kernel = kernel.reshape(list(reversed(conv_layer.get_weights()[0].shape)))\n",
    "                    kernel = kernel.transpose([2,3,1,0])\n",
    "                    conv_layer.set_weights([kernel])\n",
    "            except ValueError:\n",
    "                print(\"no convolution #\" + str(i))     \n",
    "    \n",
    "    def reset(self):\n",
    "        self.offset = 0\n",
    "\n",
    "class BoundBox:\n",
    "    def __init__(self, xmin, ymin, xmax, ymax, objness = None, classes = None):\n",
    "        self.xmin = xmin\n",
    "        self.ymin = ymin\n",
    "        self.xmax = xmax\n",
    "        self.ymax = ymax\n",
    "        \n",
    "        self.objness = objness\n",
    "        self.classes = classes\n",
    "\n",
    "        self.label = -1\n",
    "        self.score = -1\n",
    "\n",
    "    def get_label(self):\n",
    "        if self.label == -1:\n",
    "            self.label = np.argmax(self.classes)\n",
    "        \n",
    "        return self.label\n",
    "    \n",
    "    def get_score(self):\n",
    "        if self.score == -1:\n",
    "            self.score = self.classes[self.get_label()]\n",
    "            \n",
    "        return self.score\n",
    "\n",
    "def _conv_block(inp, convs, skip=True):\n",
    "    x = inp\n",
    "    count = 0\n",
    "    \n",
    "    for conv in convs:\n",
    "        if count == (len(convs) - 2) and skip:\n",
    "            skip_connection = x\n",
    "        count += 1\n",
    "        \n",
    "        if conv['stride'] > 1: x = ZeroPadding2D(((1,0),(1,0)))(x) # peculiar padding as darknet prefer left and top\n",
    "        x = Conv2D(conv['filter'], \n",
    "                   conv['kernel'], \n",
    "                   strides=conv['stride'], \n",
    "                   padding='valid' if conv['stride'] > 1 else 'same', # peculiar padding as darknet prefer left and top\n",
    "                   name='conv_' + str(conv['layer_idx']), \n",
    "                   use_bias=False if conv['bnorm'] else True)(x)\n",
    "        if conv['bnorm']: x = BatchNormalization(epsilon=0.001, name='bnorm_' + str(conv['layer_idx']))(x)\n",
    "        if conv['leaky']: x = LeakyReLU(alpha=0.1, name='leaky_' + str(conv['layer_idx']))(x)\n",
    "\n",
    "    return add([skip_connection, x]) if skip else x\n",
    "\n",
    "def _interval_overlap(interval_a, interval_b):\n",
    "    x1, x2 = interval_a\n",
    "    x3, x4 = interval_b\n",
    "\n",
    "    if x3 < x1:\n",
    "        if x4 < x1:\n",
    "            return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x1\n",
    "    else:\n",
    "        if x2 < x3:\n",
    "             return 0\n",
    "        else:\n",
    "            return min(x2,x4) - x3          \n",
    "\n",
    "def _sigmoid(x):\n",
    "    return 1. / (1. + np.exp(-x))\n",
    "\n",
    "def bbox_iou(box1, box2):\n",
    "    intersect_w = _interval_overlap([box1.xmin, box1.xmax], [box2.xmin, box2.xmax])\n",
    "    intersect_h = _interval_overlap([box1.ymin, box1.ymax], [box2.ymin, box2.ymax])\n",
    "    \n",
    "    intersect = intersect_w * intersect_h\n",
    "\n",
    "    w1, h1 = box1.xmax-box1.xmin, box1.ymax-box1.ymin\n",
    "    w2, h2 = box2.xmax-box2.xmin, box2.ymax-box2.ymin\n",
    "    \n",
    "    union = w1*h1 + w2*h2 - intersect\n",
    "    \n",
    "    return float(intersect) / union\n",
    "\n",
    "def make_yolov3_model():\n",
    "    input_image = Input(shape=(None, None, 3))\n",
    "\n",
    "    # Layer  0 => 4\n",
    "    x = _conv_block(input_image, [{'filter': 32, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 0},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 1},\n",
    "                                  {'filter': 32, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 2},\n",
    "                                  {'filter': 64, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 3}])\n",
    "\n",
    "    # Layer  5 => 8\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 5},\n",
    "                        {'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 6},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 7}])\n",
    "\n",
    "    # Layer  9 => 11\n",
    "    x = _conv_block(x, [{'filter':  64, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 9},\n",
    "                        {'filter': 128, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 10}])\n",
    "\n",
    "    # Layer 12 => 15\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 12},\n",
    "                        {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 13},\n",
    "                        {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 14}])\n",
    "\n",
    "    # Layer 16 => 36\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 16+i*3},\n",
    "                            {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 17+i*3}])\n",
    "        \n",
    "    skip_36 = x\n",
    "        \n",
    "    # Layer 37 => 40\n",
    "    x = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 37},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 38},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 39}])\n",
    "\n",
    "    # Layer 41 => 61\n",
    "    for i in range(7):\n",
    "        x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 41+i*3},\n",
    "                            {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 42+i*3}])\n",
    "        \n",
    "    skip_61 = x\n",
    "        \n",
    "    # Layer 62 => 65\n",
    "    x = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 2, 'bnorm': True, 'leaky': True, 'layer_idx': 62},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 63},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 64}])\n",
    "\n",
    "    # Layer 66 => 74\n",
    "    for i in range(3):\n",
    "        x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 66+i*3},\n",
    "                            {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 67+i*3}])\n",
    "        \n",
    "    # Layer 75 => 79\n",
    "    x = _conv_block(x, [{'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 75},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 76},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 77},\n",
    "                        {'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 78},\n",
    "                        {'filter':  512, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 79}], skip=False)\n",
    "\n",
    "    # Layer 80 => 82\n",
    "    yolo_82 = _conv_block(x, [{'filter': 1024, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 80},\n",
    "                              {'filter':  255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 81}], skip=False)\n",
    "\n",
    "    # Layer 83 => 86\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 84}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_61])\n",
    "\n",
    "    # Layer 87 => 91\n",
    "    x = _conv_block(x, [{'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 87},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 88},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 89},\n",
    "                        {'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 90},\n",
    "                        {'filter': 256, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True, 'layer_idx': 91}], skip=False)\n",
    "\n",
    "    # Layer 92 => 94\n",
    "    yolo_94 = _conv_block(x, [{'filter': 512, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 92},\n",
    "                              {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 93}], skip=False)\n",
    "\n",
    "    # Layer 95 => 98\n",
    "    x = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True, 'leaky': True,   'layer_idx': 96}], skip=False)\n",
    "    x = UpSampling2D(2)(x)\n",
    "    x = concatenate([x, skip_36])\n",
    "\n",
    "    # Layer 99 => 106\n",
    "    yolo_106 = _conv_block(x, [{'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 99},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 100},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 101},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 102},\n",
    "                               {'filter': 128, 'kernel': 1, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 103},\n",
    "                               {'filter': 256, 'kernel': 3, 'stride': 1, 'bnorm': True,  'leaky': True,  'layer_idx': 104},\n",
    "                               {'filter': 255, 'kernel': 1, 'stride': 1, 'bnorm': False, 'leaky': False, 'layer_idx': 105}], skip=False)\n",
    "\n",
    "    model = Model(input_image, [yolo_82, yolo_94, yolo_106])    \n",
    "    return model\n",
    "\n",
    "def preprocess_input(image, net_h, net_w):\n",
    "    new_h, new_w, _ = image.shape\n",
    "\n",
    "    # determine the new size of the image\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)/new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)/new_h\n",
    "        new_h = net_h\n",
    "\n",
    "    # resize the image to the new size\n",
    "    resized = cv2.resize(image[:,:,::-1]/255., (int(new_w), int(new_h)))\n",
    "\n",
    "    # embed the image into the standard letter box\n",
    "    new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "    new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "    new_image = np.expand_dims(new_image, 0)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "def decode_netout(netout, anchors, obj_thresh, nms_thresh, net_h, net_w):\n",
    "    grid_h, grid_w = netout.shape[:2]\n",
    "    nb_box = 3\n",
    "    netout = netout.reshape((grid_h, grid_w, nb_box, -1))\n",
    "    nb_class = netout.shape[-1] - 5\n",
    "\n",
    "    boxes = []\n",
    "\n",
    "    netout[..., :2]  = _sigmoid(netout[..., :2])\n",
    "    netout[..., 4:]  = _sigmoid(netout[..., 4:])\n",
    "    netout[..., 5:]  = netout[..., 4][..., np.newaxis] * netout[..., 5:]\n",
    "    netout[..., 5:] *= netout[..., 5:] > obj_thresh\n",
    "\n",
    "    for i in range(grid_h*grid_w):\n",
    "        row = i / grid_w\n",
    "        col = i % grid_w\n",
    "        \n",
    "        for b in range(nb_box):\n",
    "            # 4th element is objectness score\n",
    "            objectness = netout[int(row)][int(col)][b][4]\n",
    "            #objectness = netout[..., :4]\n",
    "            \n",
    "            if(objectness.all() <= obj_thresh): continue\n",
    "            \n",
    "            # first 4 elements are x, y, w, and h\n",
    "            x, y, w, h = netout[int(row)][int(col)][b][:4]\n",
    "\n",
    "            x = (col + x) / grid_w # center position, unit: image width\n",
    "            y = (row + y) / grid_h # center position, unit: image height\n",
    "            w = anchors[2 * b + 0] * np.exp(w) / net_w # unit: image width\n",
    "            h = anchors[2 * b + 1] * np.exp(h) / net_h # unit: image height  \n",
    "            \n",
    "            # last elements are class probabilities\n",
    "            classes = netout[int(row)][col][b][5:]\n",
    "            \n",
    "            box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, objectness, classes)\n",
    "            #box = BoundBox(x-w/2, y-h/2, x+w/2, y+h/2, None, classes)\n",
    "\n",
    "            boxes.append(box)\n",
    "\n",
    "    return boxes\n",
    "\n",
    "def correct_yolo_boxes(boxes, image_h, image_w, net_h, net_w):\n",
    "    if (float(net_w)/image_w) < (float(net_h)/image_h):\n",
    "        new_w = net_w\n",
    "        new_h = (image_h*net_w)/image_w\n",
    "    else:\n",
    "        new_h = net_w\n",
    "        new_w = (image_w*net_h)/image_h\n",
    "        \n",
    "    for i in range(len(boxes)):\n",
    "        x_offset, x_scale = (net_w - new_w)/2./net_w, float(new_w)/net_w\n",
    "        y_offset, y_scale = (net_h - new_h)/2./net_h, float(new_h)/net_h\n",
    "        \n",
    "        boxes[i].xmin = int((boxes[i].xmin - x_offset) / x_scale * image_w)\n",
    "        boxes[i].xmax = int((boxes[i].xmax - x_offset) / x_scale * image_w)\n",
    "        boxes[i].ymin = int((boxes[i].ymin - y_offset) / y_scale * image_h)\n",
    "        boxes[i].ymax = int((boxes[i].ymax - y_offset) / y_scale * image_h)\n",
    "        \n",
    "def do_nms(boxes, nms_thresh):\n",
    "    if len(boxes) > 0:\n",
    "        nb_class = len(boxes[0].classes)\n",
    "    else:\n",
    "        return\n",
    "        \n",
    "    for c in range(nb_class):\n",
    "        sorted_indices = np.argsort([-box.classes[c] for box in boxes])\n",
    "\n",
    "        for i in range(len(sorted_indices)):\n",
    "            index_i = sorted_indices[i]\n",
    "\n",
    "            if boxes[index_i].classes[c] == 0: continue\n",
    "\n",
    "            for j in range(i+1, len(sorted_indices)):\n",
    "                index_j = sorted_indices[j]\n",
    "\n",
    "                if bbox_iou(boxes[index_i], boxes[index_j]) >= nms_thresh:\n",
    "                    boxes[index_j].classes[c] = 0\n",
    "                    \n",
    "def draw_boxes(image, boxes, line, labels, obj_thresh, dcnt):\n",
    "    print(line)\n",
    "\n",
    "    for box in boxes:\n",
    "        label_str = ''\n",
    "        label = -1\n",
    "        \n",
    "        for i in range(len(labels)):\n",
    "            if box.classes[i] > obj_thresh:\n",
    "                label_str += labels[i]\n",
    "                label = i\n",
    "                print(labels[i] + ': ' + str(box.classes[i]*100) + '%')\n",
    "                print('line: (' + str(line[0][0]) + ', ' + str(line[0][1]) + ') (' + str(line[1][0]) + ', ' + str(line[1][1]) + ')')\n",
    "                print('Box: (' + str(box.xmin) + ', ' + str(box.ymin) + ') (' + str(box.xmax) + ', ' + str(box.ymax) + ')')\n",
    "                print()\n",
    "                \n",
    "        if label >= 0:\n",
    "            tf = False\n",
    "\n",
    "            (rxmin, rymin) = (box.xmin, box.ymin)\n",
    "            (rxmax, rymax) = (box.xmax, box.ymax)\n",
    "\n",
    "            tf = False\n",
    "            tf |= intersection(line[0], line[1], (rxmin, rymin), (rxmin, rymax))\n",
    "            tf |= intersection(line[0], line[1], (rxmax, rymin), (rxmax, rymax))\n",
    "            tf |= intersection(line[0], line[1], (rxmin, rymin), (rxmax, rymin))\n",
    "            tf |= intersection(line[0], line[1], (rxmin, rymax), (rxmax, rymax))\n",
    "\n",
    "            print(tf)\n",
    "\n",
    "            cv2.line(image, line[0], line[1], (255, 0, 0), 3)\n",
    "\n",
    "            if tf:\n",
    "                cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (255,0,0), 3)\n",
    "                cimg = image[box.ymin:box.ymax, box.xmin:box.xmax]\n",
    "                cv2.imshow(\"violation\", cimg)\n",
    "                cv2.waitKey(5)\n",
    "                cv2.imwrite(\"G:/Traffic Violation Detection/Traffic Signal Violation Detection System/Detected Images/violation_\"+str(dcnt)+\".jpg\", cimg)\n",
    "                dcnt = dcnt+1\n",
    "            else:\n",
    "                cv2.rectangle(image, (box.xmin,box.ymin), (box.xmax,box.ymax), (0,255,0), 3)\n",
    "\n",
    "            cv2.putText(image, \n",
    "                        label_str + ' ' + str(round(box.get_score(), 2)), \n",
    "                        (box.xmin, box.ymin - 13), \n",
    "                        cv2.FONT_ROBOTO_SIMPLEX, \n",
    "                        1e-3 * image.shape[0], \n",
    "                        (0,255,0), 2)\n",
    "        \n",
    "    return image\n",
    "\n",
    "weights_path = r\"C:\\Users\\rupsa\\OneDrive\\Documents\\traffic rules violation\\yolov3.weights\"\n",
    "# set some parameters\n",
    "net_h, net_w = 416, 416\n",
    "obj_thresh, nms_thresh = 0.5, 0.45\n",
    "anchors = [[116,90,  156,198,  373,326],  [30,61, 62,45,  59,119], [10,13,  16,30,  33,23]]\n",
    "labels = [\"person\", \"bicycle\", \"car\", \"motorbike\", \"aeroplane\", \"bus\", \"train\", \"truck\", \\\n",
    "          \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\", \"parking meter\", \"bench\", \\\n",
    "          \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\", \"elephant\", \"bear\", \"zebra\", \"giraffe\", \\\n",
    "          \"backpack\", \"umbrella\", \"handbag\", \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \\\n",
    "          \"sports ball\", \"kite\", \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \\\n",
    "          \"tennis racket\", \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\", \\\n",
    "          \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\", \"donut\", \"cake\", \\\n",
    "          \"chair\", \"sofa\", \"pottedplant\", \"bed\", \"diningtable\", \"toilet\", \"tvmonitor\", \"laptop\", \"mouse\", \\\n",
    "          \"remote\", \"keyboard\", \"cell phone\", \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \\\n",
    "          \"book\", \"clock\", \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"]\n",
    "\n",
    "# make the yolov3 model to predict 80 classes on COCO\n",
    "yolov3 = make_yolov3_model()\n",
    "\n",
    "# load the weights trained on COCO into the model\n",
    "weight_reader = WeightReader(weights_path)\n",
    "weight_reader.load_weights(yolov3)\n",
    "\n",
    "# my defined functions\n",
    "def intersection(p, q, r, t):\n",
    "    print(p, q, r, t)\n",
    "    (x1, y1) = p\n",
    "    (x2, y2) = q\n",
    "\n",
    "    (x3, y3) = r\n",
    "    (x4, y4) = t\n",
    "\n",
    "    a1 = y1-y2\n",
    "    b1 = x2-x1\n",
    "    c1 = x1*y2-x2*y1\n",
    "\n",
    "    a2 = y3-y4\n",
    "    b2 = x4-x3\n",
    "    c2 = x3*y4-x4*y3\n",
    "\n",
    "    if(a1*b2-a2*b1 == 0):\n",
    "        return False\n",
    "    print((a1, b1, c1), (a2, b2, c2))\n",
    "    x = (b1*c2 - b2*c1) / (a1*b2 - a2*b1)\n",
    "    y = (a2*c1 - a1*c2) / (a1*b2 - a2*b1)\n",
    "    print((x, y))\n",
    "\n",
    "    if x1 > x2:\n",
    "        tmp = x1\n",
    "        x1 = x2\n",
    "        x2 = tmp\n",
    "    if y1 > y2:\n",
    "        tmp = y1\n",
    "        y1 = y2\n",
    "        y2 = tmp\n",
    "    if x3 > x4:\n",
    "        tmp = x3\n",
    "        x3 = x4\n",
    "        x4 = tmp\n",
    "    if y3 > y4:\n",
    "        tmp = y3\n",
    "        y3 = y4\n",
    "        y4 = tmp\n",
    "\n",
    "    if x >= x1 and x <= x2 and y >= y1 and y <= y2 and x >= x3 and x <= x4 and y >= y3 and y <= y4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ada3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\python3.10\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"D:\\python3.10\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"D:\\python3.10\\Scripts\\pip.exe\\__main__.py\", line 4, in <module>\n",
      "ModuleNotFoundError: No module named 'pip'\n"
     ]
    }
   ],
   "source": [
    "!pip install pyimage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6c9143",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\", line 169, in _get_ffmpeg_api\n",
      "    import imageio_ffmpeg\n",
      "ModuleNotFoundError: No module named 'imageio_ffmpeg'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python3.10\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\rupsa\\AppData\\Local\\Temp\\ipykernel_2228\\1052215244.py\", line 47, in open_file\n",
      "    reader = imageio.get_reader(self.filename)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\v2.py\", line 134, in get_reader\n",
      "    return image_file.legacy_get_reader(**kwargs)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py\", line 114, in legacy_get_reader\n",
      "    return self._format.get_reader(self._request)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\core\\format.py\", line 220, in get_reader\n",
      "    return self.Reader(self, request)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\core\\format.py\", line 311, in __init__\n",
      "    self._open(**self.request.kwargs.copy())\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\", line 271, in _open\n",
      "    self._ffmpeg_api = _get_ffmpeg_api()\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\", line 171, in _get_ffmpeg_api\n",
      "    raise ImportError(\n",
      "ImportError: To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(285, 421), (1128, 442)]\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\", line 169, in _get_ffmpeg_api\n",
      "    import imageio_ffmpeg\n",
      "ModuleNotFoundError: No module named 'imageio_ffmpeg'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\python3.10\\lib\\tkinter\\__init__.py\", line 1921, in __call__\n",
      "    return self.func(*args)\n",
      "  File \"C:\\Users\\rupsa\\AppData\\Local\\Temp\\ipykernel_2228\\1052215244.py\", line 102, in imgClick\n",
      "    self.main_process()\n",
      "  File \"C:\\Users\\rupsa\\AppData\\Local\\Temp\\ipykernel_2228\\1052215244.py\", line 162, in main_process\n",
      "    reader = imageio.get_reader(video_src)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\v2.py\", line 134, in get_reader\n",
      "    return image_file.legacy_get_reader(**kwargs)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\core\\legacy_plugin_wrapper.py\", line 114, in legacy_get_reader\n",
      "    return self._format.get_reader(self._request)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\core\\format.py\", line 220, in get_reader\n",
      "    return self.Reader(self, request)\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\core\\format.py\", line 311, in __init__\n",
      "    self._open(**self.request.kwargs.copy())\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\", line 271, in _open\n",
      "    self._ffmpeg_api = _get_ffmpeg_api()\n",
      "  File \"D:\\python3.10\\lib\\site-packages\\imageio\\plugins\\ffmpeg.py\", line 171, in _get_ffmpeg_api\n",
      "    raise ImportError(\n",
      "ImportError: To use the imageio ffmpeg plugin you need to 'pip install imageio-ffmpeg'\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "from PIL import Image, ImageTk\n",
    "from tkinter import filedialog\n",
    "\n",
    "import imageio\n",
    "import cv2\n",
    "\n",
    "class Window(Frame):\n",
    "    def __init__(self, master=None):\n",
    "        Frame.__init__(self, master)\n",
    "\n",
    "        self.master = master\n",
    "        self.pos = []\n",
    "        self.line = []\n",
    "        self.rect = []\n",
    "        self.master.title(\"GUI\")\n",
    "        self.pack(fill=BOTH, expand=1)\n",
    "\n",
    "        self.counter = 0\n",
    "\n",
    "        menu = Menu(self.master)\n",
    "        self.master.config(menu=menu)\n",
    "\n",
    "        file = Menu(menu)\n",
    "        file.add_command(label=\"Open\", command=self.open_file)\n",
    "        file.add_command(label=\"Exit\", command=self.client_exit)\n",
    "        menu.add_cascade(label=\"File\", menu=file)\n",
    "        \n",
    "        analyze = Menu(menu)\n",
    "        analyze.add_command(label=\"Region of Interest\", command=self.regionOfInterest)\n",
    "        menu.add_cascade(label=\"Analyze\", menu=analyze)\n",
    "\n",
    "        self.filename = r\"stop_sign 2.jpg\"\n",
    "        self.imgSize = Image.open(self.filename)\n",
    "        self.tkimage =  ImageTk.PhotoImage(self.imgSize)\n",
    "        self.w, self.h = (1366, 768)\n",
    "        \n",
    "        self.canvas = Canvas(master = root, width = self.w, height = self.h)\n",
    "        self.canvas.create_image(20, 20, image=self.tkimage, anchor= NW)\n",
    "        self.canvas.pack()\n",
    "\n",
    "    def open_file(self):\n",
    "        self.filename = filedialog.askopenfilename()\n",
    "\n",
    "        cap = cv2.VideoCapture(self.filename)\n",
    "\n",
    "        reader = imageio.get_reader(self.filename)\n",
    "        fps = reader.get_meta_data()['fps'] \n",
    "\n",
    "        ret, image = cap.read()\n",
    "        cv2.imwrite(r'C:\\Users\\rupsa\\OneDrive\\Documents\\traffic rules violation/copy.jpg', image)\n",
    "\n",
    "        self.show_image(r'C:\\Users\\rupsa\\OneDrive\\Documents\\traffic rules violation/preview.jpg')\n",
    "\n",
    "\n",
    "    def show_image(self, frame):\n",
    "        self.imgSize = Image.open(frame)\n",
    "        self.tkimage =  ImageTk.PhotoImage(self.imgSize)\n",
    "        self.w, self.h = (1366, 768)\n",
    "\n",
    "        self.canvas.destroy()\n",
    "\n",
    "        self.canvas = Canvas(master = root, width = self.w, height = self.h)\n",
    "        self.canvas.create_image(0, 0, image=self.tkimage, anchor='nw')\n",
    "        self.canvas.pack()\n",
    "\n",
    "    def regionOfInterest(self):\n",
    "        root.config(cursor=\"plus\") \n",
    "        self.canvas.bind(\"<Button-1>\", self.imgClick) \n",
    "\n",
    "    def client_exit(self):\n",
    "        exit()\n",
    "\n",
    "    def imgClick(self, event):\n",
    "\n",
    "        if self.counter < 2:\n",
    "            x = int(self.canvas.canvasx(event.x))\n",
    "            y = int(self.canvas.canvasy(event.y))\n",
    "            self.line.append((x, y))\n",
    "            self.pos.append(self.canvas.create_line(x - 5, y, x + 5, y, fill=\"red\", tags=\"crosshair\"))\n",
    "            self.pos.append(self.canvas.create_line(x, y - 5, x, y + 5, fill=\"red\", tags=\"crosshair\"))\n",
    "            self.counter += 1\n",
    "\n",
    "\n",
    "        if self.counter == 2:\n",
    "            #unbinding action with mouse-click\n",
    "            self.canvas.unbind(\"<Button-1>\")\n",
    "            root.config(cursor=\"arrow\")\n",
    "            self.counter = 0\n",
    "\n",
    "            #show created virtual line\n",
    "            print(self.line)\n",
    "            print(self.rect)\n",
    "            img = cv2.imread(r'C:\\Users\\rupsa\\OneDrive\\Documents\\traffic rules violation/preview.jpg')\n",
    "            cv2.line(img, self.line[0], self.line[1], (0, 255, 0), 3)\n",
    "            cv2.imwrite(r'C:\\Users\\rupsa\\OneDrive\\Documents\\traffic rules violation/copy.jpg', img)\n",
    "            self.show_image(r'C:\\Users\\rupsa\\OneDrive\\Documents\\traffic rules violation/copy.jpg')\n",
    "\n",
    "            ## for demonstration\n",
    "          \n",
    "            #image processing\n",
    "            self.main_process()\n",
    "            print(\"Executed Successfully!!!\")\n",
    "\n",
    "            #clearing things\n",
    "            self.line.clear()\n",
    "            self.rect.clear()\n",
    "            for i in self.pos:\n",
    "                self.canvas.delete(i)\n",
    "\n",
    "    def intersection(self, p, q, r, t):\n",
    "        print(p, q, r, t)\n",
    "        (x1, y1) = p\n",
    "        (x2, y2) = q\n",
    "\n",
    "        (x3, y3) = r\n",
    "        (x4, y4) = t\n",
    "\n",
    "        a1 = y1-y2\n",
    "        b1 = x2-x1\n",
    "        c1 = x1*y2-x2*y1\n",
    "\n",
    "        a2 = y3-y4\n",
    "        b2 = x4-x3\n",
    "        c2 = x3*y4-x4*y3\n",
    "\n",
    "        if(a1*b2-a2*b1 == 0):\n",
    "            return False\n",
    "        print((a1, b1, c1), (a2, b2, c2))\n",
    "        x = (b1*c2 - b2*c1) / (a1*b2 - a2*b1)\n",
    "        y = (a2*c1 - a1*c2) / (a1*b2 - a2*b1)\n",
    "        print((x, y))\n",
    "\n",
    "        if x1 > x2:\n",
    "            tmp = x1\n",
    "            x1 = x2\n",
    "            x2 = tmp\n",
    "        if y1 > y2:\n",
    "            tmp = y1\n",
    "            y1 = y2\n",
    "            y2 = tmp\n",
    "        if x3 > x4:\n",
    "            tmp = x3\n",
    "            x3 = x4\n",
    "            x4 = tmp\n",
    "        if y3 > y4:\n",
    "            tmp = y3\n",
    "            y3 = y4\n",
    "            y4 = tmp\n",
    "\n",
    "        if x >= x1 and x <= x2 and y >= y1 and y <= y2 and x >= x3 and x <= x4 and y >= y3 and y <= y4:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def main_process(self):\n",
    "\n",
    "        video_src = self.filename\n",
    "\n",
    "        cap = cv2.VideoCapture(video_src)\n",
    "\n",
    "        reader = imageio.get_reader(video_src)\n",
    "        fps = reader.get_meta_data()['fps']    \n",
    "        writer = imageio.get_writer('test1.mp4', fps = fps)\n",
    "            \n",
    "        j = 1\n",
    "        while True:\n",
    "            ret, image = cap.read()\n",
    "           \n",
    "            if (type(image) == type(None)):\n",
    "                writer.close()\n",
    "                break\n",
    "            \n",
    "            image_h, image_w, _ = image.shape\n",
    "            new_image = od.preprocess_input(image, od.net_h, od.net_w)\n",
    "\n",
    "            # run the prediction\n",
    "            yolos = od.yolov3.predict(new_image)\n",
    "            boxes = []\n",
    "\n",
    "            for i in range(len(yolos)):\n",
    "                # decode the output of the network\n",
    "                boxes += od.decode_netout(yolos[i][0], od.anchors[i], od.obj_thresh, od.nms_thresh, od.net_h, od.net_w)\n",
    "\n",
    "            # correct the sizes of the bounding boxes\n",
    "            od.correct_yolo_boxes(boxes, image_h, image_w, od.net_h, od.net_w)\n",
    "\n",
    "            # suppress non-maximal boxes\n",
    "            od.do_nms(boxes, od.nms_thresh)     \n",
    "\n",
    "            # draw bounding boxes on the image using labels\n",
    "            image2 = od.draw_boxes(image, boxes, self.line, od.labels, od.obj_thresh, j) \n",
    "            \n",
    "            writer.append_data(image2)\n",
    "\n",
    "           \n",
    "            cv2.imshow('Traffic Violation', image2)\n",
    "            \n",
    "            print(j)\n",
    "\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                writer.close()\n",
    "                break\n",
    "\n",
    "            j = j+1\n",
    "\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "root = Tk()\n",
    "app = Window(root)\n",
    "root.geometry(\"%dx%d\"%(535, 380))\n",
    "root.title(\"Traffic Rule Violation\")\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae12de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio-ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779e041e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c0299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
